{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8269a048",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 4.477199,
     "end_time": "2023-09-11T12:14:11.010679",
     "exception": false,
     "start_time": "2023-09-11T12:14:06.533480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishnu/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "380f164e",
   "metadata": {
    "papermill": {
     "duration": 0.011802,
     "end_time": "2023-09-11T12:14:11.028193",
     "exception": false,
     "start_time": "2023-09-11T12:14:11.016391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Make sure you have added an accelerator to your notebook; the submission will fail otherwise!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# It's really important to add an accelerator to your notebook, as otherwise the submission will fail.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# We recomment using the P100 GPU rather than T4 as it's faster and will increase the chances of passing the time cut-off threshold.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEVICE \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMake sure you have added an accelerator to your notebook; the submission will fail otherwise!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Make sure you have added an accelerator to your notebook; the submission will fail otherwise!"
     ]
    }
   ],
   "source": [
    "# It's really important to add an accelerator to your notebook, as otherwise the submission will fail.\n",
    "# We recomment using the P100 GPU rather than T4 as it's faster and will increase the chances of passing the time cut-off threshold.\n",
    "\n",
    "if DEVICE != 'cuda':\n",
    "    raise RuntimeError('Make sure you have added an accelerator to your notebook; the submission will fail otherwise!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a067839b",
   "metadata": {
    "papermill": {
     "duration": 0.018421,
     "end_time": "2023-09-11T12:14:11.050195",
     "exception": false,
     "start_time": "2023-09-11T12:14:11.031774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper functions for loading the hidden dataset.\n",
    "\n",
    "def load_example(df_row):\n",
    "    image = torchvision.io.read_image(df_row['image_path'])\n",
    "    result = {\n",
    "        'image': image,\n",
    "        'image_id': df_row['image_id'],\n",
    "        'age_group': df_row['age_group'],\n",
    "        'age': df_row['age'],\n",
    "        'person_id': df_row['person_id']\n",
    "    }\n",
    "    return result\n",
    "\n",
    "\n",
    "class HiddenDataset(Dataset):\n",
    "    '''The hidden dataset.'''\n",
    "    def __init__(self, split='train'):\n",
    "        super().__init__()\n",
    "        self.examples = []\n",
    "\n",
    "        df = pd.read_csv(f'/kaggle/input/neurips-2023-machine-unlearning/{split}.csv')\n",
    "        df['image_path'] = df['image_id'].apply(\n",
    "            lambda x: os.path.join('/kaggle/input/neurips-2023-machine-unlearning/', 'images', x.split('-')[0], x.split('-')[1] + '.png'))\n",
    "        df = df.sort_values(by='image_path')\n",
    "        df.apply(lambda row: self.examples.append(load_example(row)), axis=1)\n",
    "        if len(self.examples) == 0:\n",
    "            raise ValueError('No examples.')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        example = self.examples[idx]\n",
    "        image = example['image']\n",
    "        image = image.to(torch.float32)\n",
    "        example['image'] = image\n",
    "        return example\n",
    "\n",
    "\n",
    "def get_dataset(batch_size):\n",
    "    '''Get the dataset.'''\n",
    "    retain_ds = HiddenDataset(split='retain')\n",
    "    forget_ds = HiddenDataset(split='forget')\n",
    "    val_ds = HiddenDataset(split='validation')\n",
    "\n",
    "    retain_loader = DataLoader(retain_ds, batch_size=batch_size, shuffle=True)\n",
    "    forget_loader = DataLoader(forget_ds, batch_size=batch_size, shuffle=True)\n",
    "    validation_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return retain_loader, forget_loader, validation_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6c9028e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T12:14:11.058602Z",
     "iopub.status.busy": "2023-09-11T12:14:11.058347Z",
     "iopub.status.idle": "2023-09-11T12:14:11.065706Z",
     "shell.execute_reply": "2023-09-11T12:14:11.064861Z"
    },
    "papermill": {
     "duration": 0.014104,
     "end_time": "2023-09-11T12:14:11.067887",
     "exception": false,
     "start_time": "2023-09-11T12:14:11.053783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can replace the below simple unlearning with your own unlearning function.\n",
    "\n",
    "def unlearning(\n",
    "    net, \n",
    "    retain_loader, \n",
    "    forget_loader, \n",
    "    val_loader):\n",
    "    \"\"\"Simple unlearning by finetuning.\"\"\"\n",
    "    epochs = 1\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, T_max=epochs)\n",
    "    net.train()\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        net.train()\n",
    "        for sample in retain_loader:\n",
    "            inputs = sample[\"image\"]\n",
    "            targets = sample[\"age_group\"]\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "    net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fbfebdb",
   "metadata": {
    "papermill": {
     "duration": 0.020651,
     "end_time": "2023-09-11T12:14:11.092174",
     "exception": false,
     "start_time": "2023-09-11T12:14:11.071523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 30] Read-only file system: '/kaggle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      3\u001b[0m     subprocess\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtouch submission.zip\u001b[39m\u001b[38;5;124m'\u001b[39m, shell\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m     \n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Note: it's really important to create the unlearned checkpoints outside of the working directory \u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# as otherwise this notebook may fail due to running out of disk space.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# The below code saves them in /kaggle/tmp to avoid that issue.\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/tmp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     retain_loader, forget_loader, validation_loader \u001b[38;5;241m=\u001b[39m get_dataset(\u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m     12\u001b[0m     net \u001b[38;5;241m=\u001b[39m resnet18(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m tail \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;66;03m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/kaggle'"
     ]
    }
   ],
   "source": [
    "if os.path.exists('/kaggle/input/neurips-2023-machine-unlearning/empty.txt'):\n",
    "    # mock submission\n",
    "    subprocess.run('touch submission.zip', shell=True)\n",
    "else:\n",
    "    \n",
    "    # Note: it's really important to create the unlearned checkpoints outside of the working directory \n",
    "    # as otherwise this notebook may fail due to running out of disk space.\n",
    "    # The below code saves them in /kaggle/tmp to avoid that issue.\n",
    "    \n",
    "    os.makedirs('/kaggle/tmp', exist_ok=True)\n",
    "    retain_loader, forget_loader, validation_loader = get_dataset(64)\n",
    "    net = resnet18(weights=None, num_classes=10)\n",
    "    net.to(DEVICE)\n",
    "    for i in range(512):\n",
    "        net.load_state_dict(torch.load('/kaggle/input/neurips-2023-machine-unlearning/original_model.pth'))\n",
    "        unlearning(net, retain_loader, forget_loader, validation_loader)\n",
    "        state = net.state_dict()\n",
    "        torch.save(state, f'/kaggle/tmp/unlearned_checkpoint_{i}.pth')\n",
    "        \n",
    "    # Ensure that submission.zip will contain exactly 512 checkpoints \n",
    "    # (if this is not the case, an exception will be thrown).\n",
    "    unlearned_ckpts = os.listdir('/kaggle/tmp')\n",
    "    if len(unlearned_ckpts) != 512:\n",
    "        raise RuntimeError('Expected exactly 512 checkpoints. The submission will throw an exception otherwise.')\n",
    "        \n",
    "    subprocess.run('zip submission.zip /kaggle/tmp/*.pth', shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7985e767-1060-4b7d-946b-b19c4370d506",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9.151114,
   "end_time": "2023-09-11T12:14:12.316499",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-09-11T12:14:03.165385",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
